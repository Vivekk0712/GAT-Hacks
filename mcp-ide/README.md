# MCP-IDE Module

**Context-Aware AI Coding Tutor** - A Cursor-like AI assistance system for web-based learning.

> ğŸ¯ Built for AdaptEd | ğŸ”’ Privacy-First | ğŸ“ Educational Focus

## What is This?

MCP-IDE is a standalone web-based code editor with an AI tutor that:
- âœ… Understands your code context (cursor position, errors, selections)
- âœ… Provides Socratic guidance (asks questions, doesn't give answers)
- âœ… Runs locally for privacy (no cloud API costs)
- âœ… Integrates easily into existing applications

Think **Cursor IDE** meets **Educational AI Tutor** in your browser.

## ğŸš€ Quick Start (5 Minutes)

### Prerequisites
- Node.js 18+ and Python 3.10+
- **Choose one:**
  - [Ollama](https://ollama.ai/download) for local LLM (requires 8GB+ RAM)
  - [Gemini API Key](https://makersuite.google.com/app/apikey) for cloud LLM (works on any machine)

### One-Command Start

**Windows:**
```cmd
start-dev.bat
```

**macOS/Linux:**
```bash
chmod +x start-dev.sh && ./start-dev.sh
```

Then open: http://localhost:5174

### Manual Start

**Option A: Using Ollama (Local)**
```bash
ollama pull llama3
```

**Option B: Using Gemini (Cloud)**
1. Get API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Add to `backend/.env`: `GEMINI_API_KEY=your_key_here`

See [GEMINI_SETUP.md](GEMINI_SETUP.md) for detailed Gemini setup.

2. **Start Backend**
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python main.py
```

3. **Start Frontend**
```bash
cd frontend
npm install
npm run dev
```

## ğŸ“š Documentation

| Document | Purpose |
|----------|---------|
| [QUICK_REFERENCE.md](QUICK_REFERENCE.md) | Commands, URLs, quick tips |
| [SETUP.md](SETUP.md) | Detailed setup instructions |
| [GEMINI_SETUP.md](GEMINI_SETUP.md) | Using Gemini instead of Ollama |
| [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md) | Complete project overview |
| [INTEGRATION.md](INTEGRATION.md) | How to integrate with AdaptEd |
| [ARCHITECTURE_DIAGRAM.md](ARCHITECTURE_DIAGRAM.md) | Visual architecture |
| [TEAM_CHECKLIST.md](TEAM_CHECKLIST.md) | Team onboarding checklist |
| [IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md) | What's done, what's next |
| [database/README.md](database/README.md) | Database schema & RAG setup |

## ğŸ¯ Key Features

### For Students
- ğŸ’¬ Chat with AI tutor about your code
- ğŸ“ Get Socratic guidance (not direct answers)
- ğŸ” Context-aware help based on cursor position
- ğŸš« Educational guardrails prevent cheating

### For Developers
- ğŸ¨ Monaco Editor (VS Code in browser)
- âš¡ Fast local LLM (Ollama)
- ğŸ”Œ Easy API integration
- ğŸ“¦ Standalone or integrated deployment

### For Privacy
- ğŸ”’ All code analysis runs locally (with Ollama)
- ğŸ  No cloud API calls required (optional Gemini)
- ğŸ›¡ï¸ GDPR/FERPA compliant by design
- ğŸ” Student code never leaves their machine (Ollama mode)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Monaco Editor  â”‚ â† User writes code
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Captures context
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚ â† Sends to backend
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP POST
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backendâ”‚ â† Builds prompt
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Calls Ollama
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ollama (Local) â”‚ â† Generates response
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Returns guidance
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chat Panel    â”‚ â† Displays hint
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Why |
|-------|-----------|-----|
| **Editor** | Monaco Editor | VS Code quality in browser |
| **Frontend** | React 19 + TypeScript | Modern, type-safe |
| **Backend** | FastAPI + Python | Fast, async, documented |
| **AI** | Ollama + Llama 3 (Local) OR Gemini (Cloud) | Local privacy or cloud convenience |
| **Styling** | Tailwind CSS | Rapid development |

## ğŸ“Š Project Structure

```
mcp-ide/
â”œâ”€â”€ frontend/                 # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/IDEPage.tsx    # Main IDE component
â”‚   â”‚   â”œâ”€â”€ types/editor.ts      # TypeScript types
â”‚   â”‚   â””â”€â”€ lib/utils.ts         # Utilities
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                  # FastAPI application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/endpoints/       # API routes
â”‚   â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ models/              # Data models
â”‚   â”‚   â””â”€â”€ core/                # Configuration
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ main.py
â”‚
â””â”€â”€ docs/                     # All documentation
```

## ğŸ“ How It Works

1. **Student writes code** in Monaco Editor
2. **System captures context**: cursor position, errors, selections
3. **Student asks question** in chat
4. **Backend builds prompt** with code context
5. **Ollama generates** Socratic response
6. **Student receives hint** (not the answer)

## ğŸ”— Integration with AdaptEd

This module is designed to integrate seamlessly:

```bash
# Copy to main frontend
cp -r mcp-ide/frontend/src/pages/IDEPage.tsx AdaptEd/frontend/src/pages/

# Add route
<Route path="/ide" element={<IDEPage />} />
```

See [INTEGRATION.md](INTEGRATION.md) for complete guide.

## ğŸ§ª Testing

### Quick Test
1. Open http://localhost:5174
2. Type some code in the editor
3. Ask "What does this code do?"
4. Should receive Socratic guidance

### API Test
```bash
curl -X POST http://localhost:8000/api/v1/tutor/ask \
  -H "Content-Type: application/json" \
  -d '{
    "editor_state": {
      "file_path": "test.js",
      "language": "javascript",
      "full_code": "function test() { return 42; }",
      "cursor_line": 1,
      "cursor_column": 1,
      "selected_text": "",
      "errors": []
    },
    "user_question": "What does this function do?"
  }'
```

## ğŸ› Troubleshooting

| Problem | Solution |
|---------|----------|
| Ollama not responding | Run `ollama list` to check |
| Backend won't start | Check Python version (3.10+) |
| Frontend errors | Clear node_modules and reinstall |
| API calls failing | Verify backend on port 8000 |

See [QUICK_REFERENCE.md](QUICK_REFERENCE.md) for more.

## ğŸ“ˆ What's Next?

### Completed âœ…
- Monaco Editor integration
- Context capture
- AI tutor with Socratic prompting
- Local LLM integration
- Chat interface

### In Progress ğŸš§
- RAG for documentation
- Multi-file support
- Error detection enhancement

### Planned ğŸ“‹
- Voice input (Whisper)
- Code execution sandbox
- Collaborative editing
- Mobile support

See [IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md) for details.

## ğŸ¤ Contributing

1. Read [TEAM_CHECKLIST.md](TEAM_CHECKLIST.md)
2. Set up local environment
3. Pick a task from [IMPLEMENTATION_STATUS.md](IMPLEMENTATION_STATUS.md)
4. Make changes and test
5. Submit for review

## ğŸ“ Support

- ğŸ“– Check [QUICK_REFERENCE.md](QUICK_REFERENCE.md) first
- ğŸ”§ Review [SETUP.md](SETUP.md) for setup issues
- ğŸ—ï¸ See [ARCHITECTURE_DIAGRAM.md](ARCHITECTURE_DIAGRAM.md) for design questions
- ğŸ“š Read [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md) for overview

## ğŸ¯ Success Metrics

- âœ… Editor loads without errors
- âœ… Can type and edit code
- âœ… Chat sends and receives messages
- âœ… Responses are educational (not direct answers)
- âœ… No console errors
- âœ… Fast response times (< 5 seconds)

## ğŸ“„ License

Part of the AdaptEd project.

## ğŸ™ Acknowledgments

Built following the architecture specifications in:
- `docs/ai_assisted_web_ide_architecture.md`
- `docs/ai_web_ide_implementation_stories.md`

Inspired by Cursor IDE and educational AI principles.

---

**Ready to start?** Run `start-dev.bat` (Windows) or `./start-dev.sh` (macOS/Linux)

**Need help?** Check [QUICK_REFERENCE.md](QUICK_REFERENCE.md)

**Want to integrate?** Read [INTEGRATION.md](INTEGRATION.md)
